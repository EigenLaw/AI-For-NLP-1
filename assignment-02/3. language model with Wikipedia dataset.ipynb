{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "import os\n",
    "from hanziconv import HanziConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the text from Wikipedia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*>')\n",
    "    cleantext = re.sub(cleanr, ' ', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "TEXT = \"\"\n",
    "dirname = 'D:/Machine Learning/NLP/data/zhwiki_partial'\n",
    "for root, dirs, files in os.walk(dirname):\n",
    "    for filename in files:\n",
    "        file_path = root + '/' + filename\n",
    "        for line in open(file_path, encoding='utf8'):\n",
    "            sline = line.strip()\n",
    "            if sline == \"\": continue\n",
    "            rline = cleanhtml(sline)\n",
    "            TEXT += ' '.join(re.findall('[\\w|\\d]+', HanziConv.toSimplified(rline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.289 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "ALL_TOKENS = list(jieba.cut(TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20085646"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ALL_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokens = [t for t in ALL_TOKENS if t.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16916508"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(valid_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 984482),\n",
       " ('在', 255052),\n",
       " ('年', 205285),\n",
       " ('是', 182671),\n",
       " ('和', 157701),\n",
       " ('了', 125501),\n",
       " ('为', 115853),\n",
       " ('与', 91322),\n",
       " ('有', 87614),\n",
       " ('月', 85988)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_all = [f for w, f in words_count.most_common()]\n",
    "frequencies_sum = sum(frequencies_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16916508"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(word):\n",
    "    esp = 1 / frequencies_sum\n",
    "    if word in words_count:\n",
    "        return words_count[word] / frequencies_sum\n",
    "    else:\n",
    "        return esp\n",
    "\n",
    "def product(numbers):\n",
    "    return reduce(lambda n1, n2: n1 * n2, numbers)\n",
    "\n",
    "def language_model_one_gram(string):\n",
    "    words = list(jieba.cut(string))\n",
    "    return product([get_prob(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2080963111330184e-16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_one_gram('数学是有趣的学科')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.473819612522043e-17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_one_gram('我晚上去上课')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4097179320104287e-20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_one_gram('长征火箭下周发射')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"\"\"\n",
    "这是一个比较正常的句子\n",
    "这个一个比较罕见的句子\n",
    "小明毕业于清华大学\n",
    "小明毕业于秦华大学\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一个比较正常的句子 6.040556831807112e-21\n",
      "这个一个比较罕见的句子 9.5917256504427e-21\n",
      "小明毕业于清华大学 4.883891421472945e-18\n",
      "小明毕业于秦华大学 5.86043206824639e-24\n"
     ]
    }
   ],
   "source": [
    "for s in sentences:\n",
    "    print(s, language_model_one_gram(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明天晚上请你吃大餐，我们一起吃苹果 is more possible\n",
      "---- 今天晚上请你吃大餐，我们一起吃日料 with probility 9.341578703953339e-54\n",
      "---- 明天晚上请你吃大餐，我们一起吃苹果 with probility 4.5342585863035046e-52\n",
      "真是一只好看的小猫 is more possible\n",
      "---- 真事一只好看的小猫 with probility 4.570949067777483e-26\n",
      "---- 真是一只好看的小猫 with probility 3.694664498661956e-23\n",
      "今晚我去吃火锅 is more possible\n",
      "---- 我去吃火锅，今晚 with probility 6.567623455714128e-28\n",
      "---- 今晚我去吃火锅 with probility 1.1110125472957569e-20\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"今天晚上请你吃大餐，我们一起吃日料 明天晚上请你吃大餐，我们一起吃苹果\",\n",
    "    \"真事一只好看的小猫 真是一只好看的小猫\",\n",
    "    \"我去吃火锅，今晚 今晚我去吃火锅\"\n",
    "]\n",
    "\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = language_model_one_gram(s1), language_model_one_gram(s2)\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    \n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_2_grams_words = [''.join(valid_tokens[i:i+2]) for i in range(len(valid_tokens[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2_gram_sum = len(all_2_grams_words)\n",
    "_2_gram_counter = Counter(all_2_grams_words)\n",
    "\n",
    "def get_combination_prob(w1, w2):\n",
    "    if w1 + w2 in _2_gram_counter:\n",
    "        return _2_gram_counter[w1+w2] / _2_gram_sum\n",
    "    else:\n",
    "        return 1 / _2_gram_sum\n",
    "    \n",
    "def get_prob_2_gram(w1, w2):\n",
    "    return get_combination_prob(w1, w2) / get_prob(w1)\n",
    "\n",
    "def language_model_of_2_gram(sentence):\n",
    "    sentences_probability = 1\n",
    "    words = list(jieba.cut(sentence))\n",
    "    for i, word in enumerate(words):\n",
    "        if i == 0:\n",
    "            prob = get_prob(word)\n",
    "        else:\n",
    "            previous = words[i - 1]\n",
    "            prob = get_prob_2_gram(previous, word)\n",
    "        sentences_probability *= prob\n",
    "    return sentences_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5471442945043766e-18"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_of_2_gram('小明今天抽奖抽到一台苹果手机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.307665875739169e-12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_of_2_gram('自然语言处理取得重大进展')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我喜欢学习算法 is more possible\n",
      "---- 我喜欢学习算法 with probility 1.4204430920006666e-12\n",
      "---- 算法学习喜欢我 with probility 3.580948971430252e-14\n",
      "今天晚上请你吃大餐，我们一起吃日料 is more possible\n",
      "---- 今天晚上请你吃大餐，我们一起吃日料 with probility 2.83516590784376e-26\n",
      "---- 明天晚上请你吃大餐，我们一起吃苹果 with probility 5.670331815687517e-27\n",
      "真是一只好看的小猫 is more possible\n",
      "---- 真事一只好看的小猫 with probility 9.760013771756896e-20\n",
      "---- 真是一只好看的小猫 with probility 1.989090571518405e-16\n",
      "今晚我去吃火锅 is more possible\n",
      "---- 今晚我去吃火锅 with probility 2.858776967945884e-14\n",
      "---- 今晚火锅去吃我 with probility 1.0803097640123967e-15\n",
      "我想去喝奶茶 is more possible\n",
      "---- 我想去喝奶茶 with probility 1.8369059633459546e-13\n",
      "---- 奶茶想去我喝 with probility 3.4782342656190107e-17\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"我喜欢学习算法 算法学习喜欢我\",\n",
    "    \"今天晚上请你吃大餐，我们一起吃日料 明天晚上请你吃大餐，我们一起吃苹果\",\n",
    "    \"真事一只好看的小猫 真是一只好看的小猫\",\n",
    "    \"今晚我去吃火锅 今晚火锅去吃我\",\n",
    "    \"我想去喝奶茶 奶茶想去我喝\"\n",
    "]\n",
    "\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = language_model_of_2_gram(s1), language_model_of_2_gram(s2)\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    \n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q: If we need to solve following problems, how can language model help us?\n",
    "* Voice Recognization.\n",
    "* Sogou pinyin input.\n",
    "* Auto correction in search engine.\n",
    "* Abnormal Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 在语义识别、搜狗拼音输入检测、搜索引擎自动纠错、异常检测等任务中，语言模型可以量化语句出现的概率即该语句正常出现的可能性，辅助系统提供合理程度最高的语句推荐给用户，供用户选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q: Compared to the previous learned parsing and pattern match problems. What's the advantage and disavantage of Probability Based Methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 基于概率的模型简单直观易理解，解决了基于模式匹配方法不能解决的复杂问题。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
